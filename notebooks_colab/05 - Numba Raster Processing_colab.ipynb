{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab only\n",
    "\u2757 This notebook is designed to run on google colab.   \n",
    "\ud83c\udf89 These top few cells should install the nescesary libraries needed and set you up to be able to run the rest of the notebook!\n",
    "\n",
    "You should already have a google account ready to go!\n",
    "\n",
    "To bore you with details, these cells will:\n",
    "- Install needed packages which are not already installed google-colab\n",
    "- Mount your google drive ready to be used \n",
    "\n",
    "### \ud83e\uddd9\u200d\u2640\ufe0f Wizards\n",
    "\ud83e\uddd9\u200d\u2642\ufe0f If you're a wizard, here's some info about colab you may want to know:\n",
    "- Each colab notebook runs on its own temporary linux virtual machine with its own filesystem.   \n",
    "- If your notebook is shutdown, this will delete the temporary instance - this is why you need to mount google drive\n",
    "- Colab seems to let you have about 3 notebook instances running at any time; each of these will be on their own unique VM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mounting google drive\n",
    "# Follow the prompts with default settings\n",
    "import os\n",
    "from os.path import join\n",
    "\n",
    "from google.colab import drive\n",
    "google_dir = '/content/drive'\n",
    "drive.mount(google_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "project_dir = Path(google_dir) / 'MyDrive' / \"ASDAF_workshop_data\"\n",
    "storage_location = project_dir / \"workshop_data\"\n",
    "\n",
    "storage_location.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Now list the contents to see whats in it. If this is the first time you've run this,\n",
    "# \"storage_location\" may be empty!\n",
    "!ls {project_dir}\n",
    "!ls {storage_location}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now ensure the data we need is in the correct place\n",
    "!wget --no-verbose --output-document shp_data.zip https://github.com/AustralianSDAF/ASDAF_Workshop_Materials_Remote_Sensing_Intro/releases/download/shapefile_data_v1.0/john_forrest_rough.zip  \n",
    "!unzip shp_data.zip -o -d ../shp_data\n",
    "# Now list the contents to make sure we see the 4 shapefile components (.dbf, .prj, .shp, and .shx)\n",
    "!echo \n",
    "!echo Shapefile folder contains:\n",
    "!ls -al ../shp_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell has been automatically inserted from build_scripts/colab_nb_builder.py\n",
    "# It should make this notebook google-colab compatible!\n",
    "\n!pip install -q --upgrade pip \n",
    "!pip install -q folium\n",
    "!pip install -q rioxarray\n",
    "!pip install -q geopandas\n",
    "!pip install -q earthpy\n",
    "!pip install -q numba\n",
    "!pip install -q numpy\n",
    "!pip install -q pandas\n",
    "!pip install -q matplotlib\n",
    "!pip install -q xarray\n",
    "!pip install -q tqdm\n",
    "!pip install -q pystac-client",
    "!echo All done! Test below if it works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Raster calculations using Numba\n",
    "## \u2753 Questions\n",
    "- How do I create fast custom raster calculations that have more flexibility than basic operations?\n",
    "\n",
    "\n",
    "## \u2757 Objectives\n",
    "- Create a `numba` compiled function that operates on multiple single pixels.\n",
    "- Create a `numba` compiled function that operates on multiple pixels at once.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Numba?\n",
    "Python has several features that make it a great prototyping language, but it's native speed is often criticised. While this is ultimately down to the implementation, it is still an issue.  \n",
    "\n",
    "Numpy and several other libraries will wrap compiled C, C++, or Fortran code to try to have the benefits of Python without giving up too much speed.  \n",
    "\n",
    "[Numba](https://numba.pydata.org/) takes a different approach. When you wrap a Python function with a `numba` compilation 'decorator', it will try to compile it using the state-of-the-art LLVM compiler. \n",
    "One drawback is that it will only run with a subset of Python and `numpy` functionality - most libraries will not be able to be compiled.\n",
    "One of the better features of `numba` is that you can write loops and the compiler will automatically optimise your code to be as fast or faster than single line `numpy` functions.  \n",
    "\n",
    "\"\n",
    "You don't need to replace the Python interpreter, run a separate compilation step, or even have a C/C++ compiler installed. Just apply one of the Numba decorators to your Python function, and Numba does the rest. \n",
    "\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example function\n",
    "Let's write an example function in `numba` to get the hang of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit\n",
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timing the code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that while `numba` can create fast custom calculations, your implementation may not always be as fast as an existing implementation due to a number of factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial setup\n",
    "Some parameters we'll need throughout the lesson.  \n",
    "> **GOOGLE COLAB**  \n",
    "> If you're on google colab, the variable in this cell will already have been set in the top-cells, so just comment it out below with a `#` like so:\n",
    "> ```py\n",
    "> # storage_location = '../workshop_data'\n",
    "> ```\n",
    "> Alternatively delete the cell, or just dont run it!\n",
    "\n",
    "If you're not on clab, run the cell by holding `Shift` then pressing `Enter`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you're on google colab, DONT RUN THIS CELL!\n",
    "storage_location = '../workshop_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying numba to remote sensing data\n",
    "Let's load back in our data and create a function to apply to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the directory again\n",
    "import os\n",
    "\n",
    "base_product_dir = os.path.join(storage_location, 'S2')\n",
    "\n",
    "# Get a dictionary of images\n",
    "import rioxarray\n",
    "from os.path import join\n",
    "\n",
    "images = {}\n",
    "files_to_load = [\n",
    "    \"nir.tif\",\n",
    "    \"red.tif\",\n",
    "    \"visual.tif\",\n",
    "]\n",
    "for fname in files_to_load:\n",
    "    fpath = join(base_product_dir, fname)\n",
    "    band = fname.split('.')[-2]\n",
    "    images[band] = rioxarray.open_rasterio(fpath)\n",
    "\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What data type is it?\n",
    "images['red'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert the `uint16` data to `float32`. To do this we will need to take the integer and divide by 10000 to get a reflectance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red = images['red'].astype(np.float32)/10000\n",
    "nir = images['nir'].astype(np.float32)/10000\n",
    "red.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NDVI\n",
    "For some more practice, let's reimplement the NDVI using `numba`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time this code and compare it to the previous way of creating an NDVI. Is it worth it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply a kernel\n",
    "We just applied a single pixel operation. Let's now use a more real-world use case, applying a kernel over an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}