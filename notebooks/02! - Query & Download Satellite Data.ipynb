{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying Satellite Data\n",
    "\n",
    "## ❓ Questions\n",
    "-  Where can I find open-access satellite data?\n",
    "-  How do I search for satellite imagery?\n",
    "-  How do I fetch remote raster datasets using Python?\n",
    "\n",
    "\n",
    "## ❗ Objectives\n",
    "-  Search public STAC repositories of satellite imagery using Python.\n",
    "-  Inspect a search result’s metadata.\n",
    "-  Download (a subset of) the assets available for a satellite scene.\n",
    "-  Open satellite imagery as raster data and save it to disk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Introduction\n",
    "A number of satellites take snapshots of the Earth’s surface from space. The images recorded by these remote sensors represent a very precious data source for any activity that involves monitoring changes on Earth. \n",
    "\n",
    "Satellite imagery is typically provided in the form of geo-spatial raster data, with the measurements in each grid cell (“pixel”) being associated to accurate geographic coordinate information.\n",
    "\n",
    "In this lesson we will explore how to access open satellite data using Python. In particular, we will consider the Sentinel-2 data collections hosted at SARA and AWS. This dataset consists of multi-band optical images acquired by the two satellites of the Sentinel-2 mission and it is continuously updated with new images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API's\n",
    "An API is an Application Programming Interface.   \n",
    "\n",
    "It is a way of having one application talk (interface) with another application in a pre-defined way. For what we're doing, these will be using web addresses and JSON data, and will be handled by our library, `pystac-client`.   \n",
    "\n",
    "We will:\n",
    "1. First initialise `pystac-client`.\n",
    "2. Give it the information it needs.\n",
    "3. Ask it to send send the request.\n",
    "4. Investigate the results\n",
    "5. Download some of the results\n",
    "\n",
    "A useful resource will be the [pystac-client documentation](https://pystac-client.readthedocs.io/en/stable/quickstart.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial setup\n",
    "Some parameters we'll need throughout the lesson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_location = '../workshop_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialising PySTAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_url = \"https://earth-search.aws.element84.com/v1\"\n",
    "\n",
    "from pystac_client import Client\n",
    "\n",
    "client = Client.open(api_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we ask for scenes belonging to the sentinel-2-l2a collection. This dataset includes Sentinel-2 data products pre-processed at level 2A (bottom-of-atmosphere reflectance) and saved in Cloud Optimized GeoTIFF (COG) format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = \"sentinel-2-l2a\"  # Sentinel-2, Level 2A, Cloud Optimized GeoTiffs (COGs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also ask for scenes intersecting a geometry defined using the shapely library (in this case, a point):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "point = Point(116.06, -31.87) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: at this stage, we are only dealing with metadata, so no image is going to be downloaded yet. But even metadata can be quite bulky if a large number of scenes match our search! For this reason, we limit the search result to 10 items:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = client.search(\n",
    "    collections=[collection],\n",
    "    intersects=point,\n",
    "    max_items=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We submit the query and find out how many scenes match our search criteria (please note that this output can be different as more data is added to the catalog):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "658\n"
     ]
    }
   ],
   "source": [
    "print(search.matched())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we retrieve the metadata of the search results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = search.item_collection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable items is an ItemCollection object. We can check its size by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(items))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is consistent with the maximum number of items that we have set in the search criteria. We can iterate over the returned items and print these to show their IDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Item id=S2A_50HMK_20240609_0_L2A>\n",
      "<Item id=S2A_50HMK_20240530_0_L2A>\n",
      "<Item id=S2B_50HMK_20240525_0_L2A>\n",
      "<Item id=S2A_50HMK_20240520_0_L2A>\n",
      "<Item id=S2B_50HMK_20240515_0_L2A>\n",
      "<Item id=S2A_50HMK_20240510_0_L2A>\n",
      "<Item id=S2B_50HMK_20240505_0_L2A>\n",
      "<Item id=S2A_50HMK_20240430_0_L2A>\n",
      "<Item id=S2B_50HMK_20240425_0_L2A>\n",
      "<Item id=S2A_50HMK_20240420_0_L2A>\n"
     ]
    }
   ],
   "source": [
    "for item in items:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-09 02:26:42.748000+00:00\n",
      "{'coordinates': [[[115.94511956423673, -31.630657005038636],\n",
      "                  [115.93367210864355, -32.620142103515384],\n",
      "                  [116.92605631462499, -32.62446740394692],\n",
      "                  [117.10325739162559, -31.945306695260914],\n",
      "                  [117.10291301200607, -31.63497332014516],\n",
      "                  [115.94511956423673, -31.630657005038636]]],\n",
      " 'type': 'Polygon'}\n",
      "{'constellation': 'sentinel-2',\n",
      " 'created': '2024-06-09T07:52:37.950Z',\n",
      " 'datetime': '2024-06-09T02:26:42.748000Z',\n",
      " 'earthsearch:boa_offset_applied': True,\n",
      " 'earthsearch:payload_id': 'roda-sentinel2/workflow-sentinel2-to-stac/384473c15c6f1cc7771f17f884670c19',\n",
      " 'earthsearch:s3_path': 's3://sentinel-cogs/sentinel-s2-l2a-cogs/50/H/MK/2024/6/S2A_50HMK_20240609_0_L2A',\n",
      " 'eo:cloud_cover': 100,\n",
      " 'grid:code': 'MGRS-50HMK',\n",
      " 'instruments': ['msi'],\n",
      " 'mgrs:grid_square': 'MK',\n",
      " 'mgrs:latitude_band': 'H',\n",
      " 'mgrs:utm_zone': 50,\n",
      " 'platform': 'sentinel-2a',\n",
      " 'processing:software': {'sentinel2-to-stac': '0.1.1'},\n",
      " 'proj:epsg': 32750,\n",
      " 's2:cloud_shadow_percentage': 0,\n",
      " 's2:dark_features_percentage': 0,\n",
      " 's2:datastrip_id': 'S2A_OPER_MSI_L2A_DS_2APS_20240609T062831_S20240609T022500_N05.10',\n",
      " 's2:datatake_id': 'GS2A_20240609T021351_046818_N05.10',\n",
      " 's2:datatake_type': 'INS-NOBS',\n",
      " 's2:degraded_msi_data_percentage': 0.0229,\n",
      " 's2:generation_time': '2024-06-09T06:28:31.000000Z',\n",
      " 's2:granule_id': 'S2A_OPER_MSI_L2A_TL_2APS_20240609T062831_A046818_T50HMK_N05.10',\n",
      " 's2:high_proba_clouds_percentage': 98.462862,\n",
      " 's2:medium_proba_clouds_percentage': 1.534694,\n",
      " 's2:nodata_pixel_percentage': 5.159389,\n",
      " 's2:not_vegetated_percentage': 0,\n",
      " 's2:processing_baseline': '05.10',\n",
      " 's2:product_type': 'S2MSI2A',\n",
      " 's2:product_uri': 'S2A_MSIL2A_20240609T021351_N0510_R060_T50HMK_20240609T062831.SAFE',\n",
      " 's2:reflectance_conversion_factor': 0.971349120323428,\n",
      " 's2:saturated_defective_pixel_percentage': 0,\n",
      " 's2:sequence': '0',\n",
      " 's2:snow_ice_percentage': 0,\n",
      " 's2:thin_cirrus_percentage': 0.002445,\n",
      " 's2:unclassified_percentage': 0,\n",
      " 's2:vegetation_percentage': 0,\n",
      " 's2:water_percentage': 0,\n",
      " 'updated': '2024-06-09T07:52:37.950Z',\n",
      " 'view:sun_azimuth': 28.2345743824049,\n",
      " 'view:sun_elevation': 29.3123313663668}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "item = items[0]\n",
    "print(item.datetime)\n",
    "pprint(item.geometry)\n",
    "pprint(item.properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ✏ Exercise: Search satellite scenes using metadata filters\n",
    "\n",
    "\n",
    "Search for all the available Sentinel-2 scenes in the sentinel-2-l2a collection that satisfy the following criteria: - intersect a provided bounding box (use ±0.01 deg in lat/lon from the previously defined point); - have been recorded between 20 March 2020 and 30 March 2020; - have a cloud coverage smaller than 10% (hint: use the query input argument of client.search).\n",
    "\n",
    "How many scenes are available? Save the search results in GeoJSON format.\n",
    "\n",
    "Hint: Buffer the previous point, and use the `bbox` search parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Access the assets\n",
    "So far we have only discussed metadata - but how can one get to the actual images of a satellite scene (the “assets” in the STAC nomenclature)? These can be reached via links that are made available through the item’s attribute assets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['aot', 'blue', 'coastal', 'granule_metadata', 'green', 'nir', 'nir08', 'nir09', 'red', 'rededge1', 'rededge2', 'rededge3', 'scl', 'swir16', 'swir22', 'thumbnail', 'tileinfo_metadata', 'visual', 'wvp', 'aot-jp2', 'blue-jp2', 'coastal-jp2', 'green-jp2', 'nir-jp2', 'nir08-jp2', 'nir09-jp2', 'red-jp2', 'rededge1-jp2', 'rededge2-jp2', 'rededge3-jp2', 'scl-jp2', 'swir16-jp2', 'swir22-jp2', 'visual-jp2', 'wvp-jp2'])\n"
     ]
    }
   ],
   "source": [
    "assets = items[0].assets  # first item's asset dictionary\n",
    "print(assets.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print a minimal description of the available assets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aot: Aerosol optical thickness (AOT)\n",
      "blue: Blue (band 2) - 10m\n",
      "coastal: Coastal aerosol (band 1) - 60m\n",
      "granule_metadata: None\n",
      "green: Green (band 3) - 10m\n",
      "nir: NIR 1 (band 8) - 10m\n",
      "nir08: NIR 2 (band 8A) - 20m\n",
      "nir09: NIR 3 (band 9) - 60m\n",
      "red: Red (band 4) - 10m\n",
      "rededge1: Red edge 1 (band 5) - 20m\n",
      "rededge2: Red edge 2 (band 6) - 20m\n",
      "rededge3: Red edge 3 (band 7) - 20m\n",
      "scl: Scene classification map (SCL)\n",
      "swir16: SWIR 1 (band 11) - 20m\n",
      "swir22: SWIR 2 (band 12) - 20m\n",
      "thumbnail: Thumbnail image\n",
      "tileinfo_metadata: None\n",
      "visual: True color image\n",
      "wvp: Water vapour (WVP)\n",
      "aot-jp2: Aerosol optical thickness (AOT)\n",
      "blue-jp2: Blue (band 2) - 10m\n",
      "coastal-jp2: Coastal aerosol (band 1) - 60m\n",
      "green-jp2: Green (band 3) - 10m\n",
      "nir-jp2: NIR 1 (band 8) - 10m\n",
      "nir08-jp2: NIR 2 (band 8A) - 20m\n",
      "nir09-jp2: NIR 3 (band 9) - 60m\n",
      "red-jp2: Red (band 4) - 10m\n",
      "rededge1-jp2: Red edge 1 (band 5) - 20m\n",
      "rededge2-jp2: Red edge 2 (band 6) - 20m\n",
      "rededge3-jp2: Red edge 3 (band 7) - 20m\n",
      "scl-jp2: Scene classification map (SCL)\n",
      "swir16-jp2: SWIR 1 (band 11) - 20m\n",
      "swir22-jp2: SWIR 2 (band 12) - 20m\n",
      "visual-jp2: True color image\n",
      "wvp-jp2: Water vapour (WVP)\n"
     ]
    }
   ],
   "source": [
    "for key, asset in assets.items():\n",
    "    print(f\"{key}: {asset.title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/50/H/MK/2024/6/S2A_50HMK_20240609_0_L2A/thumbnail.jpg\n"
     ]
    }
   ],
   "source": [
    "print(assets[\"thumbnail\"].href)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remote raster data can be directly opened via the rioxarray library. We will learn more about this library in the next episodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray (band: 1, y: 10980, x: 10980)> Size: 241MB\n",
      "[120560400 values with dtype=uint16]\n",
      "Coordinates:\n",
      "  * band         (band) int64 8B 1\n",
      "  * x            (x) float64 88kB 4e+05 4e+05 4e+05 ... 5.097e+05 5.098e+05\n",
      "  * y            (y) float64 88kB 6.5e+06 6.5e+06 6.5e+06 ... 6.39e+06 6.39e+06\n",
      "    spatial_ref  int64 8B 0\n",
      "Attributes:\n",
      "    OVR_RESAMPLING_ALG:  AVERAGE\n",
      "    AREA_OR_POINT:       Area\n",
      "    _FillValue:          0\n",
      "    scale_factor:        1.0\n",
      "    add_offset:          0.0\n"
     ]
    }
   ],
   "source": [
    "import rioxarray\n",
    "nir_href = assets[\"nir\"].href\n",
    "nir = rioxarray.open_rasterio(nir_href)\n",
    "print(nir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then save the data to disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save whole image to disk\n",
    "import os \n",
    "\n",
    "nir_fpath = os.path.join(storage_location, \"S2\", \"nir.tif\")\n",
    "os.makedirs(os.path.dirname(nir_fpath))\n",
    "\n",
    "# nir.rio.to_raster(nir_fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since that might take a while, given there are over 10000 x 10000 = a hundred million pixels in the 10 meter NIR band, you can take a smaller subset before downloading it. Becuase the raster is a COG, we can download just what we need!\n",
    "\n",
    "Here, we specify that we want to download the first (and only) band in the tif file, and a slice of the width and height dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "nir[0,1500:2200,1500:2200].rio.to_raster(nir_fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference is 155 Megabytes for the large image vs about 1 Megabyte for the subset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# ⚡ Exercise: Downloading Landsat 8 Assets\n",
    "\n",
    "In this exercise we put in practice all the skills we have learned in this episode to retrieve images from a different mission: Landsat 8. In particular, we browse images from the Harmonized Landsat Sentinel-2 (HLS) project, which provides images from NASA’s Landsat 8 and ESA’s Sentinel-2 that have been made consistent with each other. The HLS catalog is indexed in the NASA Common Metadata Repository (CMR) and it can be accessed from the STAC API endpoint at the following URL: https://cmr.earthdata.nasa.gov/stac/LPCLOUD.\n",
    "\n",
    "- Using pystac_client, search for all assets of the Landsat 8 collection (HLSL30.v2.0) from February to March 2021, intersecting the point with longitude/latitute coordinates (-73.97, 40.78) deg.\n",
    "- Visualize an item’s thumbnail (asset key browse).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Public catalogs, protected data\n",
    "\n",
    "Publicly accessible catalogs and STAC endpoints do not necessarily imply publicly accessible data. Data providers, in fact, may limit data access to specific infrastructures and/or require authentication. For instance, the NASA CMR STAC endpoint considered in the last exercise offers publicly accessible metadata for the HLS collection, but most of the linked assets are available only for registered users (the thumbnail is publicly accessible).\n",
    "\n",
    "The authentication procedure for dataset with restricted access might differ depending on the data provider. For the NASA CMR, follow these steps in order to access data using Python:\n",
    "\n",
    "- Create a NASA Earthdata login account [here](https://urs.earthdata.nasa.gov/);\n",
    "- Set up a netrc file with your credentials, e.g. by using this [script](https://git.earthdata.nasa.gov/projects/LPDUR/repos/daac_data_download_python/browse/EarthdataLoginSetup.py);\n",
    "- Define the following environment variables:\n",
    "```\n",
    "import os\n",
    "os.environ[\"GDAL_HTTP_COOKIEFILE\"] = \"./cookies.txt\"\n",
    "os.environ[\"GDAL_HTTP_COOKIEJAR\"] = \"./cookies.txt\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing our downloaded filenames for future notebooks\n",
    "Let's now store the file we downloaded in a text file for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_directory = file_downloaded\n",
    "dir_text_filename = \"product_dir.txt\"\n",
    "\n",
    "with open(dir_text_filename, 'w') as f:\n",
    "    f.writelines(product_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other options\n",
    "Another valid choice for downloading satellite data using python is [eodag](https://eodag.readthedocs.io/en/stable/). \n",
    "\n",
    "PySTAC takes a bit more knowhow of API's to use, but gives you more freedom as well.  \n",
    "PySTAC also supports COGs, which are currently only supported by the bleeding edge `eodag-cube` library rather than `eodag` itself.  \n",
    "SARA and NCI (the locations we'd get the satellite data from for eodag) supply Sentinel-2 data as zip-files rather than COGs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
